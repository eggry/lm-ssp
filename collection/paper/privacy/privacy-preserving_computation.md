# C6. Privacy-Preserving Computation
- [2024/02] **[LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification](https://arxiv.org/abs/2402.16515)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/10] **[Locally Differentially Private Document Generation Using Zero Shot Prompting](https://arxiv.org/abs/2310.16111)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP'23_(Findings)](https://img.shields.io/badge/EMNLP'23_(Findings)-f1b800)
- [2023/09] **[Differentially Private Synthetic Data via Foundation Model APIs 1: Images](https://openreview.net/forum?id=YEhQs8POIo)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[DP-OPT: Make Large Language Model Your Differentially-Private Prompt Engineer](https://openreview.net/forum?id=Ifz3IgsEPX)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/09] **[Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting](https://openreview.net/forum?id=ztpy1gsUpT)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Improving LoRA in Privacy-preserving Federated Learning](https://openreview.net/forum?id=NLPzL6HWNl)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privacy-Preserving In-Context Learning for Large Language Models](https://openreview.net/forum?id=x4OPJ7lHVU)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation](https://openreview.net/forum?id=oZtt0pRnOl)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privately Aligning Language Models with Reinforcement Learning](https://openreview.net/forum?id=3d0OmYTNui)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass](https://arxiv.org/abs/2309.06746)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800)
- [2023/08] **[SIGMA: Secure GPT Inference with Function Secret Sharing](https://eprint.iacr.org/2023/1269)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/07] **[CipherGPT: Secure Two-Party GPT Inference](https://eprint.iacr.org/2023/1147)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/05] **[Privacy-Preserving Prompt Tuning for Large Language Model Services](https://arxiv.org/abs/2305.06212)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/05] **[Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models](https://arxiv.org/abs/2305.05973)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2022/10] **[EW-Tune: A Framework for Privately Fine-Tuning Large Language Models with Differential Privacy](https://arxiv.org/abs/2210.15042)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICDM'22_(Workshops)](https://img.shields.io/badge/ICDM'22_(Workshops)-f1b800)
